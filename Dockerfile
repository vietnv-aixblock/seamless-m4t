FROM nvidia/cuda:12.4.1-cudnn-devel-ubuntu22.04
# wowai/base-hf:v1.12.0
WORKDIR /app
COPY . ./
COPY requirements.txt .

ENV MODEL_DIR=/data/models
ENV RQ_QUEUE_NAME=default
ENV REDIS_HOST=redis
ENV REDIS_PORT=6379
ENV PORT=9090
ENV AIXBLOCK_USE_REDIS=false
ENV HOST_NAME=https://app.aixblock.io
ENV HF_TOKEN=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

RUN apt-get -qq update && \
   DEBIAN_FRONTEND=noninteractive \ 
   apt-get install --no-install-recommends --assume-yes \
    git

RUN apt-get -y purge python3.8
RUN apt-get -y autoremove

RUN apt-get install --reinstall ca-certificates
# Setup
RUN apt update && apt upgrade -y
RUN apt install software-properties-common -y
RUN add-apt-repository ppa:deadsnakes/ppa -y

# Python 3.10
RUN apt install python3.10 -y
RUN apt install python3.10-dev -y
RUN apt install python3.10-distutils -y
RUN apt install python3.10-venv -y
RUN apt install libpq-dev -y uwsgi
RUN apt install build-essential
RUN apt install -y libpq-dev python3-dev
RUN apt install -y python3-pip

RUN python3.10 -m pip install psycopg2
RUN python3.10 -m pip install python-box
RUN python3.10 -m pip install --upgrade colorama
RUN apt install -y nvidia-cuda-toolkit --fix-missing
RUN python3.10 -m pip install torch torchvision torchaudio 
RUN apt-get -qq -y install curl --fix-missing
RUN apt-get update
WORKDIR /app

ENV PYTHONUNBUFFERED=True \
    PORT=${PORT:-9090} \
    PIP_CACHE_DIR=/.cache

RUN --mount=type=cache,target=/root/.cache 
RUN python3.10 -m pip install -r requirements.txt

RUN python3.10 -m pip install --upgrade Flask

RUN python3.10 -m pip install sgl-kernel --force-reinstall --no-deps
RUN python3.10 -m pip install sglang

RUN python3.10 -m pip install flashinfer -i https://flashinfer.ai/whl/cu124/torch2.4
RUN python3.10 -m pip install decord
RUN python3.10 -m pip install python-multipart

RUN python3.10 -m pip install vllm-flash-attn
# RUN python3.10 -m pip install flash_attn==2.5.8
RUN python3.10 -m pip install vllm --pre --extra-index-url https://wheels.vllm.ai/nightly

# RUN python3.10 -m pip install cmake
# RUN python3.10 -m pip install horovod[pytorch,tensorflow,keras,mxnet,spark] 
#tensorflow,keras,mxnet,spark

RUN python3.10 -c "from huggingface_hub.hf_api import HfFolder; HfFolder.save_token('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')"

# RUN apt update -y
# RUN apt install slurmd slurmctld -y
# RUN chmod 777 /etc/slurm-llnl
# RUN cat << EOF > /etc/slurm-llnl/slurm.conf
# # slurm.conf file generated by configurator.html.
# # Put this file on all nodes of your cluster.
# # See the slurm.conf man page for more information.
# #
# ClusterName=localcluster
# SlurmctldHost=localhost
# MpiDefault=none
# ProctrackType=proctrack/linuxproc
# ReturnToService=2
# SlurmctldPidFile=/var/run/slurmctld.pid
# SlurmctldPort=6817
# SlurmdPidFile=/var/run/slurmd.pid
# SlurmdPort=6818
# SlurmdSpoolDir=/var/lib/slurm-llnl/slurmd
# SlurmUser=slurm
# StateSaveLocation=/var/lib/slurm-llnl/slurmctld
# SwitchType=switch/none
# TaskPlugin=task/none
# #
# # TIMERS
# InactiveLimit=0
# KillWait=30
# MinJobAge=300
# SlurmctldTimeout=120
# SlurmdTimeout=300
# Waittime=0
# # SCHEDULING
# SchedulerType=sched/backfill
# SelectType=select/cons_tres
# SelectTypeParameters=CR_Core
# #
# #AccountingStoragePort=
# AccountingStorageType=accounting_storage/none
# JobCompType=jobcomp/none
# JobAcctGatherFrequency=30
# JobAcctGatherType=jobacct_gather/none
# SlurmctldDebug=info
# SlurmctldLogFile=/var/log/slurm-llnl/slurmctld.log
# SlurmdDebug=info
# SlurmdLogFile=/var/log/slurm-llnl/slurmd.log
# #
# # COMPUTE NODES
# NodeName=localhost CPUs=1 RealMemory=500 State=UNKNOWN
# PartitionName=LocalQ Nodes=ALL Default=YES MaxTime=INFINITE State=UP
# EOF
# RUN chmod 755 /etc/slurm-llnl/
# RUN ln -s /etc/slurm-llnl/slurm.conf /etc/slurm/slurm.conf
# RUN service slurmctld restart 
# RUN service slurmd restart

RUN python3.10 /app/load_model.py


#AMD
# Install PyTorch ROCm version
# RUN python3.10 -m pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/rocm6.1

#GPU
# RUN python3.10 -m pip install torch==2.5.1+cxx11.abi torchvision==0.20.1+cxx11.abi torchaudio==2.5.1+cxx11.abi intel-extension-for-pytorch==2.5.10+xpu oneccl_bind_pt==2.5.0+xpu --extra-index-url https://pytorch-extension.intel.com/release-whl/stable/xpu/cn/

#CPU
# RUN python3.10 -m pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu
# RUN python3.10 -m pip install intel-extension-for-pytorch oneccl_bind_pt --extra-index-url https://pytorch-extension.intel.com/release-whl/stable/cpu/cn/

# RUN apt-get update
# RUN apt-get install --allow-downgrades --no-install-recommends -y \
# cuda-nvml-dev-11-0=11.0.167-1 \
# cuda-nvcc-11-0=11.0.221-1 \
# cuda-cudart-dev-11-0=11.0.221-1 \
# cuda-libraries-dev-11-0=11.0.3-1 \
# libnccl-dev=2.11.4-1+cuda11.5\
# libcusparse-dev-11-0=11.1.1.245-1



# COPY . ./
EXPOSE 9090 6006 12345 23456
CMD exec gunicorn --preload --bind :${PORT} --workers 1 --threads 1 --timeout 0 _wsgi:app

